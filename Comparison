# comparing CNVs from inferCNV to ASCAT results to calculate precision and recall

# create bed files in R
file <- file.path("HMM_CNV_predictions.HMMi6.leiden.hmm_mode-subclusters.Pnorm_0.5.pred_cnv_regions.dat")
seg_data <- read.table(file, header=TRUE, sep="\t")
convert_to_bed <- function(seg_dat) {
  bed_data <- data.frame(
    chrom = seg_data$chr,
    start = seg_data$start - 1,
    end = seg_data$end,
    name = seg_data$cell_group_name,
    score = seg_data$state
  )
  return(bed_data)
}
bed_data <- convert_to_bed(seg_data)
bed_file <- file.path("42D.bed")
write.table(bed_data, file = bed_file, quote = FALSE, sep = "\t", row.names = FALSE, col.names = FALSE)

# bedtools in %%bash
## sort
sort -k1,1V -k2,2n 42D.bed \
> 42D_sort.bed

## blaclist hg38 v2
module load bedtools/2.30.0
a_dir="/path/"
b_file="/research/groups/bioinformaticians/internship/aalizade/scenicplus1/blacklist/hg38-blacklist.v2.bed"
for a_file in "$a_dir"/*_sort.bed; do
    output_file="${a_file%.bed}_blck05.bed"
    bedtools intersect -a "$a_file" -b "$b_file" -f 0.50 -v > "$output_file" 
    echo "Processed $a_file and saved as $output_file"
done

## intersect
bedtools intersect -a D_42_cnvs.bed -b 42D_sort_blck05.bed -wao

## remove doublets and unique signals in scRNA
import pandas as pd

# Read the file into a pandas DataFrame (TP+FP)
file_path = "42D_sort_blck05.bed"
df = pd.read_csv(file_path, sep="\t", header=None)
df.columns = ['chr1', 'start1', 'end1', 'state1', 'cnv_name1', 'cnv_type1', 
              'cnv_size1', 'chr2', 'start2', 'end2', 'group', 'state2', 'cnv_size2']
state_mapping = {
    1: 'loss',
    2: 'loss',
    3: 'normal',
    4: 'gain',
    5: 'gain',
    6: 'gain'
}
df['state2_category'] = df['state2'].map(state_mapping)
df_unique = df.drop_duplicates(subset=['start2', 'end2', 'state2_category'])
output_path = "42D_def_rows.bed"
df_unique.to_csv(output_path, sep="\t", index=False, header=False)

## TP
file_path = "42D_def_rows.bed"
df = pd.read_csv(file_path, sep="\t", header=None)
df.columns = ['chr1', 'start1', 'end1', 'state1', 'cnv_name1', 'cnv_type1', 
              'cnv_size1', 'chr2', 'start2', 'end2', 'group', 'state2', 'cnv_size2', 'state2_category']
filtered_df = df[
    ((df['cnv_type1'] == 'DEL') & (df['state2_category'] == 'loss')) |  # DEL and loss
    ((df['cnv_type1'] == 'DUP') & (df['state2_category'] == 'gain')) |  # DUP and gain
    (df['cnv_type1'] == 'LOH')  # LOH in column 6
]
summary_counts = filtered_df.shape[0]
print(filtered_df)
print(f"Number of rows matching the criteria: {summary_counts}")
